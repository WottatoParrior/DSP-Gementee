{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbe6681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers_gvb_reworked_v2 as h\n",
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta\n",
    "from workalendar.europe import Netherlands\n",
    "import numpy as np\n",
    "from workalendar.europe import NetherlandsWithSchoolHolidays as NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fff5c424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining different weather sources\n",
    "kmni = pd.read_csv(\"weather_knmi.csv\",\",\")\n",
    "weather = pd.read_csv(\"Amsterdam_weather_new_clean.csv\",\",\")\n",
    "kmni[\"Date\"] = pd.to_datetime(kmni[\"Date\"])\n",
    "weather[\"date_time\"] = pd.to_datetime(weather[\"date_time\"])\n",
    "kmni.sort_values(by=\"Date\", inplace =True)\n",
    "kmni.reset_index(inplace = True)\n",
    "weather.sort_values(by=\"date_time\", inplace =True)\n",
    "weather.reset_index(inplace = True)\n",
    "kmni.drop(columns= [\"index\"], inplace =True)\n",
    "weather.drop(columns= [\"index\"], inplace =True)\n",
    "weather = pd.merge_asof(weather, kmni, left_on=\"date_time\", right_on =\"Date\")\n",
    "\n",
    "weather['date_time'] = pd.to_datetime(weather['date_time'],  infer_datetime_format=True )\n",
    "weather.sort_values(by=\"date_time\", inplace =True)\n",
    "weather.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "445a5507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annalorincz/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3444: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "#read in checkin and check out data\n",
    "check_in = pd.read_csv(\"check_ins_metro_preprocessed.csv\",\",\")\n",
    "check_out = pd.read_csv(\"check_out_metro_preprocessed.csv\",\",\")\n",
    "check_in.drop(columns=[\"Unnamed: 0\"], inplace = True)\n",
    "check_out.drop(columns=[\"Unnamed: 0\"], inplace = True)\n",
    "\n",
    "check_in[\"hour\"] = check_in[\"hour\"].astype(str)\n",
    "check_in[\"hour\"] = check_in[\"hour\"].str.zfill(2)\n",
    "\n",
    "check_in[\"datetime_2\"] = \"\"\n",
    "check_in[\"datetime_2\"] = check_in[\"datetime\"].astype(str) + \" \" + check_in[\"hour\"].astype(str)\n",
    "check_in[\"datetime_2\"] = pd.to_datetime(check_in[\"datetime_2\"],  infer_datetime_format=True)\n",
    "check_in.sort_values(by=\"datetime_2\", inplace =True)\n",
    "check_in.reset_index(inplace = True)\n",
    "\n",
    "\n",
    "check_out[\"hour\"] = check_out[\"hour\"].astype(str)\n",
    "check_out[\"hour\"] = check_out[\"hour\"].str.zfill(2)\n",
    "\n",
    "check_out[\"datetime_2\"] = \"\"\n",
    "check_out[\"datetime_2\"] = check_out[\"datetime\"].astype(str) + \" \" + check_out[\"hour\"].astype(str)+\":00:00\"\n",
    "check_out[\"datetime_2\"] = pd.to_datetime(check_out[\"datetime_2\"],  infer_datetime_format=True )\n",
    "check_out.sort_values(by=\"datetime_2\", inplace =True)\n",
    "check_out.reset_index(inplace = True)\n",
    "\n",
    "check_in.drop(columns= [\"index\"], inplace= True)\n",
    "check_out.drop(columns= [\"index\"], inplace = True)\n",
    "\n",
    "check_in = check_in[[\"HalteNaam\",\"AantalReizen\", \"datetime_2\", \"weekday\", \"datetime\"]]\n",
    "check_out  = check_out[[\"HalteNaam\",\"AantalReizen\", \"datetime_2\", \"weekday\", \"datetime\"]]\n",
    "check_in.rename(columns = {\"HalteNaam\":\"Station\", \"AantalReizen\":\"Checked_in_passengers\", \"datetime_2\":\"Date_time\"}, inplace= True)\n",
    "check_out.rename(columns = {\"HalteNaam\":\"Station\", \"AantalReizen\":\"Checked_out_passengers\", \"datetime_2\":\"Date_time\"}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5649e55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mjoing check_in and check_out\n",
    "GVB = check_in.merge(check_out, left_on = [\"Date_time\",\"Station\", \"weekday\", \"datetime\"], right_on = [\"Date_time\",\"Station\", \"weekday\", \"datetime\"], how = \"inner\")\n",
    "#adding new feature (adding together number of passengers checked in and out)\n",
    "GVB[\"Passengers_total\"] = GVB[\"Checked_in_passengers\"] + GVB[\"Checked_out_passengers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05f4eb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging station on line51,53,54\n",
    "Selected_51_53_54 = GVB[GVB[\"Station\"].isin([\"Nieuwmarkt\", \"Waterlooplein\", \"Weesperplein\", \"Wibautstraat\",\"Amstelstation\"])]\n",
    "\n",
    "Merged_51_53_54 = pd.DataFrame(columns = GVB.columns)\n",
    "Merged_51_53_54[\"Date_time\"] = Selected_51_53_54[\"Date_time\"].unique()\n",
    "Merged_51_53_54[\"Station\"] = \"Joined Stations Line 51,53,54\"\n",
    "\n",
    "for i in range(len(Merged_51_53_54)):\n",
    "    Merged_51_53_54.loc[i,\"Checked_in_passengers\"] = round(Selected_51_53_54[Selected_51_53_54[\"Date_time\"] == Merged_51_53_54.loc[i,\"Date_time\"]][\"Checked_in_passengers\"].mean())\n",
    "    Merged_51_53_54.loc[i,\"Checked_out_passengers\"] = round(Selected_51_53_54[Selected_51_53_54[\"Date_time\"] == Merged_51_53_54.loc[i,\"Date_time\"]][\"Checked_out_passengers\"].mean())\n",
    "    Merged_51_53_54.loc[i,\"weekday\"] = list(Selected_51_53_54[Selected_51_53_54[\"Date_time\"] == Merged_51_53_54.loc[i,\"Date_time\"]][\"weekday\"])[0]\n",
    "    Merged_51_53_54.loc[i,\"datetime\"] = list(Selected_51_53_54[Selected_51_53_54[\"Date_time\"] == Merged_51_53_54.loc[i,\"Date_time\"]][\"datetime\"])[0]\n",
    "    \n",
    "Merged_51_53_54[\"Passengers_total\"] = Merged_51_53_54[\"Checked_in_passengers\"] + Merged_51_53_54[\"Checked_out_passengers\"]\n",
    "\n",
    "\n",
    "#Mergin station on line 52 South\n",
    "Selected_52_S = GVB[GVB[\"Station\"].isin([\"Rokin\", \"Vijzelgracht\", \"De Pijp\", \"Europaplein\"])]\n",
    "\n",
    "Merged_52_S = pd.DataFrame(columns = GVB.columns)\n",
    "Merged_52_S[\"Date_time\"] = Selected_52_S[\"Date_time\"].unique()\n",
    "Merged_52_S[\"Station\"] = \"Joined Stations Line 52 South\"\n",
    "\n",
    "for i in range(len(Merged_52_S)):\n",
    "    Merged_52_S.loc[i,\"Checked_in_passengers\"] = round(Selected_52_S[Selected_52_S[\"Date_time\"] == Merged_52_S.loc[i,\"Date_time\"]][\"Checked_in_passengers\"].mean())\n",
    "    Merged_52_S.loc[i,\"Checked_out_passengers\"] = round(Selected_52_S[Selected_52_S[\"Date_time\"] == Merged_52_S.loc[i,\"Date_time\"]][\"Checked_out_passengers\"].mean())\n",
    "    Merged_52_S.loc[i,\"weekday\"] = list(Selected_52_S[Selected_52_S[\"Date_time\"] == Merged_52_S.loc[i,\"Date_time\"]][\"weekday\"])[0]\n",
    "    Merged_52_S.loc[i,\"datetime\"] = list(Selected_52_S[Selected_52_S[\"Date_time\"] == Merged_52_S.loc[i,\"Date_time\"]][\"datetime\"])[0]\n",
    "    \n",
    "Merged_52_S[\"Passengers_total\"] = Merged_52_S[\"Checked_in_passengers\"] + Merged_52_S[\"Checked_out_passengers\"]\n",
    "\n",
    "\n",
    "#Mergin station on line 52 North\n",
    "Selected_52_N = GVB[GVB[\"Station\"].isin([\"Noord\", \"Noorderpark\"])]\n",
    "\n",
    "Merged_52_N = pd.DataFrame(columns = GVB.columns)\n",
    "Merged_52_N[\"Date_time\"] = Selected_52_N[\"Date_time\"].unique()\n",
    "Merged_52_N[\"Station\"] = \"Joined Stations Line 52 North\"\n",
    "\n",
    "for i in range(len(Merged_52_N)):\n",
    "    Merged_52_N.loc[i,\"Checked_in_passengers\"] = round(Selected_52_N[Selected_52_N[\"Date_time\"] == Merged_52_N.loc[i,\"Date_time\"]][\"Checked_in_passengers\"].mean())\n",
    "    Merged_52_N.loc[i,\"Checked_out_passengers\"] = round(Selected_52_N[Selected_52_N[\"Date_time\"] == Merged_52_N.loc[i,\"Date_time\"]][\"Checked_out_passengers\"].mean())\n",
    "    Merged_52_N.loc[i,\"weekday\"] = list(Selected_52_N[Selected_52_N[\"Date_time\"] == Merged_52_N.loc[i,\"Date_time\"]][\"weekday\"])[0]\n",
    "    Merged_52_N.loc[i,\"datetime\"] = list(Selected_52_N[Selected_52_N[\"Date_time\"] == Merged_52_N.loc[i,\"Date_time\"]][\"datetime\"])[0]\n",
    "    \n",
    "Merged_52_N[\"Passengers_total\"] = Merged_52_N[\"Checked_in_passengers\"] + Merged_52_N[\"Checked_out_passengers\"]\n",
    "\n",
    "\n",
    "#Mergin station on line 50,51 \n",
    "Selected_50_51 = GVB[GVB[\"Station\"].isin([\"Westwijk\", \"Sacharovlaan\"\"Poortwachter\",\"Brink\", \"Meent\",\"Sportlaan\", \"Ouderkerkerlaan\", \"Amstelveen Stadshart\",  \"Oranjebaan\", \"Onderuit\", \"Zonnestein\" , \"Kronenburg\", \"Uilenstede\", \"Van Boshuizenstraat\", \"A.J. Ernststraat\", \"De Boelelaan/VU\", \"Isolatorweg\",  \"Station Sloterdijk\", \"Burg.de Vlugtlaan\", \"Jan van Galenstraat\" , \"Postjesweg\", \"Station Lelylaan\", \"Henk Sneevlietweg\", \"Amstelveenseweg\" ] )]\n",
    "#Spinnerij and Gondel, Marne, Heernstedestraat was not found\n",
    "\n",
    "Merged_50_51 = pd.DataFrame(columns = GVB.columns)\n",
    "Merged_50_51[\"Date_time\"] = Selected_50_51[\"Date_time\"].unique()\n",
    "Merged_50_51[\"Station\"] = \"Joined Stations Line 50,51\"\n",
    "\n",
    "for i in range(len(Merged_50_51)):\n",
    "    Merged_50_51.loc[i,\"Checked_in_passengers\"] = round(Selected_50_51[Selected_50_51[\"Date_time\"] == Merged_50_51.loc[i,\"Date_time\"]][\"Checked_in_passengers\"].mean())\n",
    "    Merged_50_51.loc[i,\"Checked_out_passengers\"] = round(Selected_50_51[Selected_50_51[\"Date_time\"] == Merged_50_51.loc[i,\"Date_time\"]][\"Checked_out_passengers\"].mean())\n",
    "    Merged_50_51.loc[i,\"weekday\"] = list(Selected_50_51[Selected_50_51[\"Date_time\"] == Merged_50_51.loc[i,\"Date_time\"]][\"weekday\"])[0]\n",
    "    Merged_50_51.loc[i,\"datetime\"] = list(Selected_50_51[Selected_50_51[\"Date_time\"] == Merged_50_51.loc[i,\"Date_time\"]][\"datetime\"])[0]\n",
    "    \n",
    "Merged_50_51[\"Passengers_total\"] = Merged_50_51[\"Checked_in_passengers\"] + Merged_50_51[\"Checked_out_passengers\"]\n",
    "\n",
    "\n",
    "#Mergin station on line 50 South\n",
    "Selected_50_S = GVB[GVB[\"Station\"].isin([\"Bullewijk\", \"Station Holendrecht\", \"Reigersbos\",\"Gein\" ])]\n",
    "\n",
    "Merged_50_S = pd.DataFrame(columns = GVB.columns)\n",
    "Merged_50_S[\"Date_time\"] = Selected_50_S[\"Date_time\"].unique()\n",
    "Merged_50_S[\"Station\"] = \"Joined Stations Line 50,54 South\"\n",
    "\n",
    "for i in range(len(Merged_50_S)):\n",
    "    Merged_50_S.loc[i,\"Checked_in_passengers\"] = round(Selected_50_S[Selected_50_S[\"Date_time\"] == Merged_50_S.loc[i,\"Date_time\"]][\"Checked_in_passengers\"].mean())\n",
    "    Merged_50_S.loc[i,\"Checked_out_passengers\"] = round(Selected_50_S[Selected_50_S[\"Date_time\"] == Merged_50_S.loc[i,\"Date_time\"]][\"Checked_out_passengers\"].mean())\n",
    "    Merged_50_S.loc[i,\"weekday\"] = list(Selected_50_S[Selected_50_S[\"Date_time\"] == Merged_50_S.loc[i,\"Date_time\"]][\"weekday\"])[0]\n",
    "    Merged_50_S.loc[i,\"datetime\"] = list(Selected_50_S[Selected_50_S[\"Date_time\"] == Merged_50_S.loc[i,\"Date_time\"]][\"datetime\"])[0]\n",
    "    \n",
    "Merged_50_S[\"Passengers_total\"] = Merged_50_S[\"Checked_in_passengers\"] + Merged_50_S[\"Checked_out_passengers\"]\n",
    "\n",
    "#Mergin station on line 53 South\n",
    "Selected_53_S = GVB[GVB[\"Station\"].isin([\"Venserpolder\", \"Station Diemen-Zuid\", \"Verrijn Stuartweg\", \"Station Ganzenhoef\", \"Kraaienneststation\", \"Gaasperplas\"])]\n",
    "\n",
    "Merged_53_S = pd.DataFrame(columns = GVB.columns)\n",
    "Merged_53_S[\"Date_time\"] = Selected_53_S[\"Date_time\"].unique()\n",
    "Merged_53_S[\"Station\"] = \"Joined Stations Line 53 South\"\n",
    "\n",
    "for i in range(len(Merged_53_S)):\n",
    "    Merged_53_S.loc[i,\"Checked_in_passengers\"] = round(Selected_53_S[Selected_53_S[\"Date_time\"] == Merged_53_S.loc[i,\"Date_time\"]][\"Checked_in_passengers\"].mean())\n",
    "    Merged_53_S.loc[i,\"Checked_out_passengers\"] = round(Selected_53_S[Selected_53_S[\"Date_time\"] == Merged_53_S.loc[i,\"Date_time\"]][\"Checked_out_passengers\"].mean())\n",
    "    Merged_53_S.loc[i,\"weekday\"] = list(Selected_53_S[Selected_53_S[\"Date_time\"] == Merged_53_S.loc[i,\"Date_time\"]][\"weekday\"])[0]\n",
    "    Merged_53_S.loc[i,\"datetime\"] = list(Selected_53_S[Selected_53_S[\"Date_time\"] == Merged_53_S.loc[i,\"Date_time\"]][\"datetime\"])[0]\n",
    "    \n",
    "Merged_53_S[\"Passengers_total\"] = Merged_53_S[\"Checked_in_passengers\"] + Merged_53_S[\"Checked_out_passengers\"]\n",
    "\n",
    "#Mergin station on line 50,51 central\n",
    "Selected_50_51_C = GVB[GVB[\"Station\"].isin([\"Station RAI\", \"Overamstel\"])]\n",
    "\n",
    "Merged_50_51_C = pd.DataFrame(columns = GVB.columns)\n",
    "Merged_50_51_C[\"Date_time\"] = Selected_50_51_C[\"Date_time\"].unique()\n",
    "Merged_50_51_C[\"Station\"] = \"Joined Stations Line 50,51 Central\"\n",
    "\n",
    "for i in range(len(Merged_50_51_C)):\n",
    "    Merged_50_51_C.loc[i,\"Checked_in_passengers\"] = round(Selected_50_51_C[Selected_50_51_C[\"Date_time\"] == Merged_50_51_C.loc[i,\"Date_time\"]][\"Checked_in_passengers\"].mean())\n",
    "    Merged_50_51_C.loc[i,\"Checked_out_passengers\"] = round(Selected_50_51_C[Selected_50_51_C[\"Date_time\"] == Merged_50_51_C.loc[i,\"Date_time\"]][\"Checked_out_passengers\"].mean())\n",
    "    Merged_50_51_C.loc[i,\"weekday\"] = list(Selected_50_51_C[Selected_50_51_C[\"Date_time\"] == Merged_50_51_C.loc[i,\"Date_time\"]][\"weekday\"])[0]\n",
    "    Merged_50_51_C.loc[i,\"datetime\"] = list(Selected_50_51_C[Selected_50_51_C[\"Date_time\"] == Merged_50_51_C.loc[i,\"Date_time\"]][\"datetime\"])[0]\n",
    "    \n",
    "Merged_50_51_C[\"Passengers_total\"] = Merged_50_51_C[\"Checked_in_passengers\"] + Merged_50_51_C[\"Checked_out_passengers\"]\n",
    "\n",
    "choosen_stations = GVB[GVB[\"Station\"].isin([\"Centraal Station\",\"Spaklerweg\", \"Van der Madeweg\" ,\"Station Duivendrecht\", \"Strandvliet\", \"Station Bijlmer ArenA\",\"Station Zuid\"])]\n",
    "\n",
    "GVB_merged = pd.concat([choosen_stations,Merged_51_53_54,Merged_52_S,Merged_52_N, Merged_50_51, Merged_50_S,Merged_53_S,Selected_50_51_C ])\n",
    "GVB_merged.sort_values(by=\"Date_time\", inplace =True)\n",
    "GVB_merged.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66fedd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating baselines\n",
    "#This baseline / average is used for both the visualization and filling in missing values\n",
    "GVB_merged[\"Date_time\"] = pd.to_datetime(GVB_merged[\"Date_time\"])\n",
    "\n",
    "for i in range(len(GVB_merged)):\n",
    "    GVB_merged.loc[i, \"Hour\"] = GVB_merged.loc[i, \"Date_time\"].hour\n",
    "\n",
    "GVB_merged[\"Checked_in_passengers\"] = pd.to_numeric(GVB_merged[\"Checked_in_passengers\"])\n",
    "GVB_merged[\"Checked_out_passengers\"] = pd.to_numeric(GVB_merged[\"Checked_out_passengers\"])\n",
    "GVB_merged[\"Passengers_total\"] = pd.to_numeric(GVB_merged[\"Passengers_total\"])\n",
    "\n",
    "grouped = GVB_merged.groupby([ 'Station', 'Hour', \"weekday\"]).agg({'Checked_in_passengers': \"mean\", \"Checked_out_passengers\":\"mean\", \"Passengers_total\":\"mean\"})\n",
    "grouped = grouped.reset_index()\n",
    "\n",
    "time_range = pd.date_range('2019-01-01T0:00', '2021-12-26T0:00', freq = 'H')\n",
    "time_ranges = list(time_range) *15\n",
    "\n",
    "baselines = pd.DataFrame(columns = ['Time_to_filter'])\n",
    "baselines[\"Time_to_filter\"] = time_ranges\n",
    "\n",
    "Stations = []\n",
    "for i in list(GVB_merged[\"Station\"].unique()):\n",
    "    for j in range(26161):\n",
    "        Stations.append(i)\n",
    "        \n",
    "baselines[\"Station\"] = Stations\n",
    "baselines[\"Time_to_filter\"] = pd.to_datetime(baselines[\"Time_to_filter\"])\n",
    "\n",
    "times_to_filter = baselines[\"Time_to_filter\"]\n",
    "weekdays_list = []\n",
    "hours_list = []\n",
    "for i in times_to_filter:\n",
    "    weekdays_list.append(i.weekday())\n",
    "    hours_list.append(i.hour)\n",
    "baselines[\"weekday\"] = weekdays_list\n",
    "baselines[\"Hour\"] = hours_list\n",
    "baselines =  baselines.merge(grouped,how=\"left\", left_on=[\"Hour\", \"Station\", \"weekday\"], right_on=[\"Hour\", \"Station\", \"weekday\"])\n",
    "baselines[\"Checked_in_passengers\"] = round(baselines[\"Checked_in_passengers\"])\n",
    "baselines[\"Checked_out_passengers\"] = round(baselines[\"Checked_out_passengers\"])\n",
    "baselines[\"Passengers_total\"] = round(baselines[\"Passengers_total\"])\n",
    "\n",
    "baselines.loc[baselines[\"Hour\"].isin([1,2,3,4]), \"Checked_in_passengers\"] = 0\n",
    "baselines.loc[baselines[\"Hour\"].isin([2,3,4,5]), \"Checked_out_passengers\"] = 0\n",
    "baselines = baselines.fillna(0)\n",
    "\n",
    "GVB_merged[\"weekday\"] = pd.to_numeric(GVB_merged[\"weekday\"])\n",
    "GVB_merged[\"Hour\"] = pd.to_numeric(GVB_merged[\"Hour\"])\n",
    "GVB_merged = GVB_merged.groupby([ 'Station', 'Date_time']).agg({'Checked_in_passengers': \"mean\", \"weekday\":\"mean\", \"Checked_out_passengers\":\"mean\", \"Passengers_total\":\"mean\",\"Hour\":\"mean\" })\n",
    "\n",
    "#merging with baseline\n",
    "baselines[\"Time_to_filter\"] = pd.to_datetime(baselines[\"Time_to_filter\"])\n",
    "baselines.rename(columns={\"Time_to_filter\":\"Date_time\", \"Checked_in_passengers\":\"Checked_in_passengers_BASELINE\", \"Checked_out_passengers\": \"Checked_out_passengers_BASELINE\", \"Passengers_total\":\"Passengers_total_BASELINE\"}, inplace = True)\n",
    "baselines = baselines[[\"Date_time\", \"Station\", \"Checked_in_passengers_BASELINE\", \"Checked_out_passengers_BASELINE\", \"Passengers_total_BASELINE\" ]]\n",
    "#filling missing values based on baseline\n",
    "GVB_merged_filled = baselines.merge(GVB_merged, how= \"left\", left_on=[\"Date_time\",\"Station\"], right_on=[\"Date_time\",\"Station\"])\n",
    "#GVB_merged_filled.to_csv(\"GVB_merged_filled.csv\")\n",
    "\n",
    "#Adding dummy:is_filled_binary\n",
    "GVB_merged_filled[\"Filled_from_baseline_binary\"] = \"\"\n",
    "GVB_merged_filled.loc[GVB_merged_filled[\"Checked_in_passengers\"].notnull(), \"Filled_from_baseline_binary\"] = 0\n",
    "GVB_merged_filled.loc[GVB_merged_filled[\"Checked_in_passengers\"].isnull(), \"Filled_from_baseline_binary\"] =  1\n",
    "\n",
    "#filling missing values from baseline\n",
    "GVB_merged_filled.loc[GVB_merged_filled[\"Checked_in_passengers\"].isnull(), \"Checked_in_passengers\"] = GVB_merged_filled.loc[GVB_merged_filled[\"Checked_in_passengers\"].isnull(), \"Checked_in_passengers_BASELINE\"]\n",
    "GVB_merged_filled.loc[GVB_merged_filled[\"Checked_out_passengers\"].isnull(), \"Checked_out_passengers\"] = GVB_merged_filled.loc[GVB_merged_filled[\"Checked_out_passengers\"].isnull(), \"Checked_out_passengers_BASELINE\"]\n",
    "GVB_merged_filled.loc[GVB_merged_filled[\"Passengers_total\"].isnull(), \"Passengers_total\"] = GVB_merged_filled.loc[GVB_merged_filled[\"Passengers_total\"].isnull(), \"Checked_out_passengers_BASELINE\"] + GVB_merged_filled.loc[GVB_merged_filled[\"Passengers_total\"].isnull(), \"Checked_in_passengers_BASELINE\"]\n",
    "#GVB_merged_filled.drop(columns=[\"index\"], inplace=True)\n",
    "weekdays_to_fill =[]\n",
    "missing_week_days = GVB_merged_filled.loc[GVB_merged_filled[\"weekday\"].isnull(), \"Date_time\"]\n",
    "for i in missing_week_days.index:\n",
    "    a = str(missing_week_days.loc[i].weekday())\n",
    "    weekdays_to_fill.append(a)\n",
    "GVB_merged_filled.loc[GVB_merged_filled[\"weekday\"].isnull(), \"weekday\"] = weekdays_to_fill\n",
    "date_to_fill =[]\n",
    "datetimes = GVB_merged_filled[\"Date_time\"]\n",
    "hours_to_fill = []\n",
    "for i in datetimes:\n",
    "    date_to_fill.append(i.date())\n",
    "    hours_to_fill.append(i.hour)\n",
    "GVB_merged_filled[\"date\"] = date_to_fill\n",
    "GVB_merged_filled[\"Hour\"] = hours_to_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e8381e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add weather data as feature (this is problematic, lot of weather data is missing)\n",
    "GVB_merged_filled.sort_values(by=\"Date_time\", inplace =True)\n",
    "GVB_merged_filled.reset_index(inplace = True)\n",
    "\n",
    "GVB_weather = pd.merge_asof(GVB_merged_filled, weather, left_on=\"Date_time\", right_on =\"date_time\")\n",
    "GVB_weather.drop(columns=[\"City\", \"index_x\", \"index_y\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cba09a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#events\n",
    "events_from_data_file = 'evenementen_zuidoost_edited_new_w_2019_fixed.xlsx'\n",
    "events  = pd.read_excel(events_from_data_file, sheet_name=\"evenementen_zuidoost_edited\", header=0,index_col=False,keep_default_na=True)\n",
    "\n",
    "events[\"Opening_datetime\"] = events[\"year\"].astype(str)+ \"-\" + events[\"month\"].astype(str) + \"-\" + events[\"day\"].astype(str) +\" \"+ events[\"TijdDeurenOpen\"].astype(str)\n",
    "events[\"Opening_datetime\"]  = pd.to_datetime(events[\"Opening_datetime\"] ,  infer_datetime_format=True)\n",
    "\n",
    "events[\"Starting_datetime\"] = events[\"year\"].astype(str)+ \"-\" + events[\"month\"].astype(str) + \"-\" + events[\"day\"].astype(str) +\" \"+ + events[\"TijdShowStart\"].astype(str)\n",
    "events[\"Starting_datetime\"]  = pd.to_datetime(events[\"Starting_datetime\"] ,  infer_datetime_format=True)\n",
    "\n",
    "events[\"Ending_datetime\"] = events[\"year\"].astype(str)+ \"-\" + events[\"month\"].astype(str) + \"-\" + events[\"day\"].astype(str) +\" \"+ + events[\"TijdEinde\"].astype(str)\n",
    "events[\"Ending_datetime\"]  = pd.to_datetime(events[\"Ending_datetime\"] ,  infer_datetime_format=True)\n",
    "\n",
    "events[\"Evenementlocatie\"] = events[\"Evenementlocatie\"].replace({'Johan Cruijff ArenA ':'Johan Cruijff ArenA', 'Ziggo dome':'Ziggo Dome', 'Ziggo Dome ':'Ziggo Dome'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25ce6be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annalorincz/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "/Users/annalorincz/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "/Users/annalorincz/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/annalorincz/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/pandas/core/indexing.py:1965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj._check_is_chained_assignment_possible()\n",
      "/Users/annalorincz/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "events_selected = events[[\"Titel\", \"Opening_datetime\", \"Starting_datetime\", \"Ending_datetime\",\"BezoekersVerwacht\",\"Evenementlocatie\", \"Evenementlocatie:Capaciteit\",\"ID\" ]]\n",
    "events_selected.loc[:,\"Set_opening_datetime\"] = \"\"\n",
    "events_selected.loc[:,\"Set_opening_datetime\"] = events_selected.loc[:,\"Starting_datetime\"] - timedelta(minutes = 60)\n",
    "\n",
    "\n",
    "merge_df_start = pd.DataFrame(columns = ['Titel',\"Set_opening_datetime\", 'Opening_datetime', 'Starting_datetime', 'Ending_datetime',\n",
    "       'BezoekersVerwacht', 'Evenementlocatie', 'Evenementlocatie:Capaciteit','ID'])\n",
    "\n",
    "events_selected[\"Set_opening_datetime\"] = events_selected[\"Set_opening_datetime\"].dt.round('15min')  \n",
    "\n",
    "events_selected.loc[:,\"Current_time\"] = events_selected.loc[:,\"Set_opening_datetime\"]\n",
    "for i in range(len(events_selected)):\n",
    "    if events_selected[\"Set_opening_datetime\"][i].minute == 0:\n",
    "        merge_df_start = merge_df_start.append(events_selected.loc[i], ignore_index = True)\n",
    "    elif events_selected[\"Set_opening_datetime\"][i].minute == 30:\n",
    "        z = events_selected.loc[i]\n",
    "        z.loc[\"BezoekersVerwacht\"] = z.loc[\"BezoekersVerwacht\"]*0.5\n",
    "        z.loc[\"Current_time\"] = z.loc[\"Set_opening_datetime\"] + timedelta(minutes = 30)\n",
    "        merge_df_start = merge_df_start.append(z, ignore_index = True)\n",
    "        z = events_selected.loc[i]\n",
    "        z.loc[\"BezoekersVerwacht\"] = z.loc[\"BezoekersVerwacht\"]*0.5\n",
    "        z.loc[\"Current_time\"] = z.loc[\"Set_opening_datetime\"] - timedelta(minutes = 30)\n",
    "        merge_df_start = merge_df_start.append(z, ignore_index = True)\n",
    "    elif events_selected[\"Set_opening_datetime\"][i].minute == 15:\n",
    "        z = events_selected.loc[i]\n",
    "        z.loc[\"BezoekersVerwacht\"] = z.loc[\"BezoekersVerwacht\"]*0.25\n",
    "        z.loc[\"Current_time\"] = z.loc[\"Set_opening_datetime\"] + timedelta(minutes = 45)\n",
    "        merge_df_start = merge_df_start.append(z, ignore_index = True)\n",
    "        z = events_selected.loc[i]\n",
    "        z.loc[\"BezoekersVerwacht\"] = z.loc[\"BezoekersVerwacht\"]*0.75\n",
    "        z.loc[\"Current_time\"] = z.loc[\"Set_opening_datetime\"] - timedelta(minutes = 15)\n",
    "        merge_df_start = merge_df_start.append(z, ignore_index = True)\n",
    "    elif events_selected[\"Set_opening_datetime\"][i].minute == 45:\n",
    "        z = events_selected.loc[i]\n",
    "        z.loc[\"BezoekersVerwacht\"] = z.loc[\"BezoekersVerwacht\"]*0.25\n",
    "        z.loc[\"Current_time\"] = z.loc[\"Set_opening_datetime\"] - timedelta(minutes = 45)\n",
    "        merge_df_start = merge_df_start.append(z, ignore_index = True)\n",
    "        z = events_selected.loc[i]\n",
    "        z.loc[\"BezoekersVerwacht\"] = z.loc[\"BezoekersVerwacht\"]*0.75\n",
    "        z.loc[\"Current_time\"] = z.loc[\"Set_opening_datetime\"] + timedelta(minutes = 15)\n",
    "        merge_df_start = merge_df_start.append(z, ignore_index = True)\n",
    "\n",
    "#I with this we only merge it to the Arena Stations later\n",
    "#merge_df_start[\"Station\"] = \"Station Bijlmer ArenA\"\n",
    "merge_df_start[\"movement_type\"] = \"Arriving to event\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03b227ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annalorincz/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Fixing events ending at weird times (like :55,:59, :5)\n",
    "events_selected[\"Ending_datetime\"] = events_selected[\"Ending_datetime\"].dt.round('15min')  \n",
    "\n",
    "\n",
    "merge_df_end = pd.DataFrame(columns = ['Titel',\"Set_opening_datetime\", 'Opening_datetime', 'Starting_datetime', 'Ending_datetime',\n",
    "       'BezoekersVerwacht', 'Evenementlocatie', 'Evenementlocatie:Capaciteit','ID', \"Current_time\"])\n",
    "\n",
    "for i in range(len(events_selected)):\n",
    "    if events_selected[\"Ending_datetime\"][i].minute == 0:\n",
    "        z = events_selected.loc[i]\n",
    "        z.loc[\"Current_time\"] = z.loc[\"Ending_datetime\"]\n",
    "        merge_df_end = merge_df_end.append(z, ignore_index = True)        \n",
    "    elif events_selected[\"Ending_datetime\"][i].minute == 30:\n",
    "        z = events_selected.loc[i]\n",
    "        z.loc[\"BezoekersVerwacht\"] = z.loc[\"BezoekersVerwacht\"]*0.5\n",
    "        z.loc[\"Current_time\"] = z.loc[\"Ending_datetime\"] + timedelta(minutes = 30)\n",
    "        merge_df_end = merge_df_end.append(z, ignore_index = True)\n",
    "        z = events_selected.loc[i]\n",
    "        z.loc[\"BezoekersVerwacht\"] = z.loc[\"BezoekersVerwacht\"]*0.5\n",
    "        z.loc[\"Current_time\"] = z.loc[\"Ending_datetime\"] - timedelta(minutes = 30)\n",
    "        merge_df_end = merge_df_end.append(z, ignore_index = True)\n",
    "    elif events_selected[\"Ending_datetime\"][i].minute == 15:\n",
    "        z = events_selected.loc[i]\n",
    "        z.loc[\"BezoekersVerwacht\"] = z.loc[\"BezoekersVerwacht\"]*0.25\n",
    "        z.loc[\"Current_time\"] = z.loc[\"Ending_datetime\"] + timedelta(minutes = 45)\n",
    "        merge_df_end = merge_df_end.append(z, ignore_index = True)\n",
    "        z = events_selected.loc[i]\n",
    "        z.loc[\"BezoekersVerwacht\"] = z.loc[\"BezoekersVerwacht\"]*0.75\n",
    "        z.loc[\"Current_time\"] = z.loc[\"Ending_datetime\"] - timedelta(minutes = 15)\n",
    "        merge_df_end = merge_df_end.append(z, ignore_index = True)\n",
    "    elif events_selected[\"Ending_datetime\"][i].minute == 45:\n",
    "        z = events_selected.loc[i]\n",
    "        z.loc[\"BezoekersVerwacht\"] = z.loc[\"BezoekersVerwacht\"]*0.25\n",
    "        z.loc[\"Current_time\"] = z.loc[\"Ending_datetime\"] - timedelta(minutes = 45)\n",
    "        merge_df_end = merge_df_end.append(z, ignore_index = True)\n",
    "        z = events_selected.loc[i]\n",
    "        z.loc[\"BezoekersVerwacht\"] = z.loc[\"BezoekersVerwacht\"]*0.75\n",
    "        z.loc[\"Current_time\"] = z.loc[\"Ending_datetime\"] + timedelta(minutes = 15)\n",
    "        merge_df_end = merge_df_end.append(z, ignore_index = True)\n",
    "\n",
    "#I with this we only merge it to the Arena Stations later\n",
    "#merge_df_end[\"Station\"] = \"Station Bijlmer ArenA\"\n",
    "\n",
    "merge_df_end[\"movement_type\"] = \"Leaving the event\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbb5774b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annalorincz/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3444: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "merged_df_all = pd.concat([merge_df_start,merge_df_end])\n",
    "GVB_weather_events_all = GVB_weather.merge(merged_df_all, left_on = [\"Date_time\"], right_on = [\"Current_time\"], how = \"left\")\n",
    "merged_df_all.reset_index(inplace = True)\n",
    "\n",
    "events_selected.to_csv(\"event_infos.csv\")\n",
    "\n",
    "date_times  = GVB_weather_events_all[\"Date_time\"]\n",
    "dates = []\n",
    "for i in date_times : \n",
    "    dates.append(i.date())\n",
    "    \n",
    "GVB_weather_events_all[\"Date_time\"] = pd.to_datetime(GVB_weather_events_all[\"Date_time\"],  infer_datetime_format=True )\n",
    "\n",
    "GVB_weather_events_all[\"Dates\"] = dates\n",
    "GVB_weather_events_all[\"Dates\"] = pd.to_datetime(GVB_weather_events_all[\"Dates\"])\n",
    "restrictions = pd.read_csv(\"restrictions_NL.csv\",\",\")\n",
    "restrictions.drop(columns=[\"C3_Flag\", \"C3_Notes\"], inplace= True)\n",
    "restrictions[\"date\"] = pd.to_datetime(restrictions[\"date\"],  infer_datetime_format=True )\n",
    "restrictions\n",
    "\n",
    "GVB_weather_events_all_covidindex = GVB_weather_events_all.merge(restrictions, left_on = \"Dates\", right_on = \"date\",how = \"left\")\n",
    "\n",
    "GVB_weather_events_all_covidindex['movement_type'] = GVB_weather_events_all_covidindex['movement_type'].fillna(\"No event\")\n",
    "GVB_weather_events_all_covidindex['BezoekersVerwacht'] = GVB_weather_events_all_covidindex['BezoekersVerwacht'].fillna(0)\n",
    "GVB_weather_events_all_covidindex['Evenementlocatie'] = GVB_weather_events_all_covidindex['Evenementlocatie'].fillna(\"No event\")\n",
    "GVB_weather_events_all_covidindex['Evenementlocatie:Capaciteit'] = GVB_weather_events_all_covidindex['Evenementlocatie:Capaciteit'].fillna(\"No event\")\n",
    "GVB_weather_events_all_covidindex['Titel'] = GVB_weather_events_all_covidindex['Titel'].fillna(\"No event\")\n",
    "GVB_weather_events_all_covidindex['StringencyIndex'] = GVB_weather_events_all_covidindex['StringencyIndex'].fillna(0)\n",
    "GVB_weather_events_all_covidindex['C3_Cancel public events'] = GVB_weather_events_all_covidindex['C3_Cancel public events'].fillna(0)\n",
    "GVB_weather_events_all_covidindex[\"weekday\"] = pd.to_numeric(GVB_weather_events_all_covidindex[\"weekday\"])\n",
    "\n",
    "GVB_weather_events_all_covidindex[\"Event starting\"] = GVB_weather_events_all_covidindex[\"movement_type\"]\n",
    "GVB_weather_events_all_covidindex[\"Event ending\"]  = GVB_weather_events_all_covidindex[\"movement_type\"]\n",
    "\n",
    "GVB_weather_events_all_covidindex[\"Event starting\"].replace({\"No event\":0,\"Arriving to event\":1, \"Leaving the event\":0}, inplace=True) \n",
    "GVB_weather_events_all_covidindex[\"Event ending\"].replace({\"No event\":0,\"Arriving to event\":0, \"Leaving the event\":1},inplace=True) \n",
    "GVB_weather_events_all_covidindex[\"Effected number of events (L/A)\"] =  GVB_weather_events_all_covidindex[\"Event ending\"]+ GVB_weather_events_all_covidindex[\"Event starting\"]\n",
    "GVB_weather_events_all_covidindex[\"Expected visitors to arrive\"] = GVB_weather_events_all_covidindex['BezoekersVerwacht']* GVB_weather_events_all_covidindex[\"Event starting\"]\n",
    "GVB_weather_events_all_covidindex[\"Expected visitors to leave\"] = GVB_weather_events_all_covidindex['BezoekersVerwacht'] * GVB_weather_events_all_covidindex[\"Event ending\"]\n",
    "\n",
    "\n",
    "\n",
    "M_GVB_weather_events_all_covidindex = GVB_weather_events_all_covidindex.groupby([ 'Station', 'Date_time']).agg({'Checked_in_passengers': \"sum\", \"Checked_out_passengers\":\"sum\", \"Passengers_total\":\"sum\",\"weekday\": \"mean\", \"BezoekersVerwacht\": \"sum\", \"StringencyIndex\": \"mean\", \"C3_Cancel public events\": \"mean\" , \"Event starting\":\"sum\", \"Event ending\":\"sum\",\"Effected number of events (L/A)\":\"sum\" , \"Expected visitors to arrive\": \"sum\",\"Expected visitors to leave\": \"sum\" , \"Checked_in_passengers_BASELINE\":\"mean\", \"Checked_out_passengers_BASELINE\":\"mean\", \"Passengers_total_BASELINE\":\"mean\" })\n",
    "M_GVB_weather_events_all_covidindex.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbd8f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add weather data as feature (this is problematic, lot of weather data is missing)\n",
    "M_GVB_weather_events_all_covidindex.sort_values(by=\"Date_time\", inplace =True)\n",
    "M_GVB_weather_events_all_covidindex.reset_index(inplace = True)\n",
    "M_GVB_weather_events_all_covidindex  = pd.merge_asof(M_GVB_weather_events_all_covidindex , weather, left_on=\"Date_time\", right_on =\"date_time\")\n",
    "M_GVB_weather_events_all_covidindex.drop(columns=[\"City\", \"index_x\", \"index_y\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09f299ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annalorincz/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/annalorincz/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#Holidays\n",
    "calendar = NL(region=\"north\", carnival_instead_of_spring=True)\n",
    " \n",
    "# Get a list of holidays\n",
    "holiday_list_2019 = calendar.holidays(2019)\n",
    "holiday_list_2020 = calendar.holidays(2020)\n",
    "holiday_list_2021 = calendar.holidays(2021)\n",
    "holiday_list = holiday_list_2019 + holiday_list_2020+holiday_list_2021 \n",
    "\n",
    "# Make a dictionary with a list of holidays for each date entry\n",
    "\n",
    "holiday_dict = {}\n",
    "for h in holiday_list:\n",
    "    holiday_dict.setdefault(h[0], []).append(h[1])\n",
    "\n",
    "dates = []\n",
    "holidays = []\n",
    "\n",
    "for i in holiday_dict:\n",
    "    dates.append(i)\n",
    "    \n",
    "for i in list(holiday_dict.values()):\n",
    "    holidays.append(i)\n",
    "\n",
    "holiday_list = pd.DataFrame({'Date' : dates,\n",
    "                                'Holiday' : holidays }, \n",
    "                                columns=['Date','Holiday'])\n",
    "\n",
    "M_GVB_weather_events_all_covidindex.rename(columns = {\"datetime\":\"Date\", \"date_time\":\"Weather Time\"}, inplace= True)\n",
    "M_GVB_weather_events_all_covidindex[\"Date\"] = pd.to_datetime(M_GVB_weather_events_all_covidindex[\"Date\"])\n",
    "holiday_list[\"Date\"] = pd.to_datetime(holiday_list[\"Date\"])\n",
    "for i in range(len(holiday_list)):\n",
    "    if len(holiday_list[\"Holiday\"][i]) == 1:\n",
    "        holiday_list[\"Holiday\"][i] = holiday_list[\"Holiday\"][i][0]\n",
    "    elif len(holiday_list[\"Holiday\"][i]) == 2:\n",
    "        holiday_list[\"Holiday\"][i] = holiday_list[\"Holiday\"][i][0] + \", \" + holiday_list[\"Holiday\"][i][1]\n",
    "        \n",
    "\n",
    "M_GVB_weather_events_all_covidindex_holidays = M_GVB_weather_events_all_covidindex.merge(holiday_list, how=\"left\", left_on=\"Date\", right_on=\"Date\")\n",
    "M_GVB_weather_events_all_covidindex_holidays[\"Holiday\"] = M_GVB_weather_events_all_covidindex_holidays[\"Holiday\"].fillna(\"Not a holiday\")\n",
    "M_GVB_weather_events_all_covidindex_holidays = pd.get_dummies(M_GVB_weather_events_all_covidindex_holidays, columns=[\"Condition\", \"C3_Cancel public events\",\"weekday\" , \"Holiday\"])\n",
    "\n",
    "M_GVB_weather_events_all_covidindex_holidays[\"Is_Holiday_Binary\"] = M_GVB_weather_events_all_covidindex_holidays[\"Holiday_Not a holiday\"]\n",
    "M_GVB_weather_events_all_covidindex_holidays[\"Is_Holiday_Binary\"].replace({1:0,0:1}, inplace=True)\n",
    "\n",
    "\n",
    "M_GVB_weather_events_all_covidindex_holidays.to_csv(\"M_GVB_weather_events_all_covidindex_holidays_filled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "570a603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#M_GVB_weather_events_all_covidindex_holidays = M_GVB_weather_events_all_covidindex_holidays[M_GVB_weather_events_all_covidindex_holidays[\"Date_time\"]>=datetime(2020,1,1)]\n",
    "\n",
    "holidays_data_raw = Netherlands().holidays(2019) + Netherlands().holidays(2020) + Netherlands().holidays(2021) \n",
    "import helpers_gvb_reworked_v2 as h\n",
    "holiday_df = h.preprocess_holiday_data(holidays_data_raw)\n",
    "holiday_df[\"Date\"] = pd.to_datetime(holiday_df[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8deb941",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_GVB_weather_events_all_covidindex['HOLIDAY_BINARY'] = np.where((M_GVB_weather_events_all_covidindex['Date'].isin(holiday_df['Date'].values)), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9da505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_GVB_weather_events_all_covidindex_holidays_binary = M_GVB_weather_events_all_covidindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4e8f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = M_GVB_weather_events_all_covidindex_holidays_binary[\"Date_time\"]\n",
    "\n",
    "years = []\n",
    "months = []\n",
    "days = []\n",
    "hours = []\n",
    "date_a_week_ago = []\n",
    "\n",
    "for i in dates:\n",
    "    years.append(i.year)\n",
    "    months.append(int(i.month))\n",
    "    days.append(i.day)\n",
    "    hours.append(int(i.hour))\n",
    "    date_a_week_ago.append(i-timedelta(days = 7))\n",
    "\n",
    "M_GVB_weather_events_all_covidindex_holidays_binary[\"Month\"] = months\n",
    "M_GVB_weather_events_all_covidindex_holidays_binary[\"Hour\"] = hours\n",
    "M_GVB_weather_events_all_covidindex_holidays_binary[\"Date_time_week_ago\"] = date_a_week_ago\n",
    "M_GVB_weather_events_all_covidindex_holidays_binary[\"Date_time_week_ago\"] = pd.to_datetime(M_GVB_weather_events_all_covidindex_holidays_binary[\"Date_time_week_ago\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11032ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annalorincz/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/Users/annalorincz/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_to_merge = M_GVB_weather_events_all_covidindex_holidays_binary[[\"Date_time\",\"Checked_in_passengers\", \"Checked_out_passengers\", \"Station\" ]]\n",
    "data_to_merge.rename(columns={\"Date_time\": \"Date_time_week_ago\", \"Checked_in_passengers\": \"Checked_in_passengers_week_ago\", \"Checked_out_passengers\": \"Checked_out_passengers_week_ago\"}, inplace = True)\n",
    "data_to_merge[\"Date_time_week_ago\"] = pd.to_datetime(data_to_merge[\"Date_time_week_ago\"])\n",
    "M_GVB_weather_events_all_covidindex_holidays_binary = M_GVB_weather_events_all_covidindex_holidays_binary.merge(data_to_merge, how = \"left\", left_on =[\"Date_time_week_ago\", \"Station\"], right_on = [\"Date_time_week_ago\", \"Station\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28d9b8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Station', 'Date_time', 'Checked_in_passengers',\n",
       "       'Checked_out_passengers', 'Passengers_total', 'weekday',\n",
       "       'BezoekersVerwacht', 'StringencyIndex', 'C3_Cancel public events',\n",
       "       'Event starting', 'Event ending', 'Effected number of events (L/A)',\n",
       "       'Expected visitors to arrive', 'Expected visitors to leave',\n",
       "       'Checked_in_passengers_BASELINE', 'Checked_out_passengers_BASELINE',\n",
       "       'Passengers_total_BASELINE', 'Temp(F)', 'Wind(MpH)', 'RainFall(in)',\n",
       "       'Condition', 'Weather Time', 'Date', 'duration_rain_knmi',\n",
       "       'avg_wind_speed_knmi', 'avg_temp_knmi', 'sum_rain_knmi',\n",
       "       'global_radiation', 'HOLIDAY_BINARY', 'Month', 'Hour',\n",
       "       'Date_time_week_ago', 'Checked_in_passengers_week_ago',\n",
       "       'Checked_out_passengers_week_ago'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_GVB_weather_events_all_covidindex_holidays_binary.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b6ef31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are only using data from 2020 and later\n",
    "M_GVB_weather_events_all_covidindex_holidays_binary2020 = M_GVB_weather_events_all_covidindex_holidays_binary[M_GVB_weather_events_all_covidindex_holidays_binary[\"Date_time\"]>=datetime(2020,1,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4a31af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Date_time</th>\n",
       "      <th>Checked_in_passengers</th>\n",
       "      <th>Checked_out_passengers</th>\n",
       "      <th>Passengers_total</th>\n",
       "      <th>weekday</th>\n",
       "      <th>BezoekersVerwacht</th>\n",
       "      <th>StringencyIndex</th>\n",
       "      <th>C3_Cancel public events</th>\n",
       "      <th>Event starting</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_wind_speed_knmi</th>\n",
       "      <th>avg_temp_knmi</th>\n",
       "      <th>sum_rain_knmi</th>\n",
       "      <th>global_radiation</th>\n",
       "      <th>HOLIDAY_BINARY</th>\n",
       "      <th>Month</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Date_time_week_ago</th>\n",
       "      <th>Checked_in_passengers_week_ago</th>\n",
       "      <th>Checked_out_passengers_week_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131400</th>\n",
       "      <td>Centraal Station</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>389.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-25</td>\n",
       "      <td>676.0</td>\n",
       "      <td>339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131401</th>\n",
       "      <td>Station Bijlmer ArenA</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>81.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-25</td>\n",
       "      <td>31.0</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131402</th>\n",
       "      <td>Station Zuid</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>61.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-25</td>\n",
       "      <td>89.0</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131403</th>\n",
       "      <td>Joined Stations Line 51,53,54</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-25</td>\n",
       "      <td>102.0</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131404</th>\n",
       "      <td>Station RAI</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>15.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-25</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392410</th>\n",
       "      <td>Centraal Station</td>\n",
       "      <td>2021-12-26</td>\n",
       "      <td>154.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.89</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-12-19</td>\n",
       "      <td>201.0</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392411</th>\n",
       "      <td>Joined Stations Line 50,54 South</td>\n",
       "      <td>2021-12-26</td>\n",
       "      <td>17.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.89</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-12-19</td>\n",
       "      <td>11.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392412</th>\n",
       "      <td>Station RAI</td>\n",
       "      <td>2021-12-26</td>\n",
       "      <td>30.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.89</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-12-19</td>\n",
       "      <td>30.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392413</th>\n",
       "      <td>Spaklerweg</td>\n",
       "      <td>2021-12-26</td>\n",
       "      <td>39.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.89</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-12-19</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392414</th>\n",
       "      <td>Van der Madeweg</td>\n",
       "      <td>2021-12-26</td>\n",
       "      <td>13.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.89</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-12-19</td>\n",
       "      <td>13.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261015 rows  34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Station  Date_time  Checked_in_passengers  \\\n",
       "131400                  Centraal Station 2020-01-01                  389.0   \n",
       "131401             Station Bijlmer ArenA 2020-01-01                   81.0   \n",
       "131402                      Station Zuid 2020-01-01                   61.0   \n",
       "131403     Joined Stations Line 51,53,54 2020-01-01                   50.0   \n",
       "131404                       Station RAI 2020-01-01                   15.0   \n",
       "...                                  ...        ...                    ...   \n",
       "392410                  Centraal Station 2021-12-26                  154.0   \n",
       "392411  Joined Stations Line 50,54 South 2021-12-26                   17.0   \n",
       "392412                       Station RAI 2021-12-26                   30.0   \n",
       "392413                        Spaklerweg 2021-12-26                   39.0   \n",
       "392414                   Van der Madeweg 2021-12-26                   13.0   \n",
       "\n",
       "        Checked_out_passengers  Passengers_total  weekday  BezoekersVerwacht  \\\n",
       "131400                   210.0             599.0      2.0                0.0   \n",
       "131401                   110.0             191.0      2.0                0.0   \n",
       "131402                    97.0             158.0      2.0                0.0   \n",
       "131403                    20.0              70.0      2.0                0.0   \n",
       "131404                    31.0              46.0      2.0                0.0   \n",
       "...                        ...               ...      ...                ...   \n",
       "392410                   100.0             254.0      6.0                0.0   \n",
       "392411                   123.0             140.0      6.0                0.0   \n",
       "392412                    83.0             113.0      6.0                0.0   \n",
       "392413                    93.0             132.0      6.0                0.0   \n",
       "392414                    46.0              59.0      6.0                0.0   \n",
       "\n",
       "        StringencyIndex  C3_Cancel public events  Event starting  ...  \\\n",
       "131400             0.00                      0.0               0  ...   \n",
       "131401             0.00                      0.0               0  ...   \n",
       "131402             0.00                      0.0               0  ...   \n",
       "131403             0.00                      0.0               0  ...   \n",
       "131404             0.00                      0.0               0  ...   \n",
       "...                 ...                      ...             ...  ...   \n",
       "392410            63.89                      2.0               0  ...   \n",
       "392411            63.89                      2.0               0  ...   \n",
       "392412            63.89                      2.0               0  ...   \n",
       "392413            63.89                      2.0               0  ...   \n",
       "392414            63.89                      2.0               0  ...   \n",
       "\n",
       "        avg_wind_speed_knmi  avg_temp_knmi  sum_rain_knmi  global_radiation  \\\n",
       "131400                 25.0            7.0            0.0             240.0   \n",
       "131401                 25.0            7.0            0.0             240.0   \n",
       "131402                 25.0            7.0            0.0             240.0   \n",
       "131403                 25.0            7.0            0.0             240.0   \n",
       "131404                 25.0            7.0            0.0             240.0   \n",
       "...                     ...            ...            ...               ...   \n",
       "392410                 66.0          -11.0            0.0             416.0   \n",
       "392411                 66.0          -11.0            0.0             416.0   \n",
       "392412                 66.0          -11.0            0.0             416.0   \n",
       "392413                 66.0          -11.0            0.0             416.0   \n",
       "392414                 66.0          -11.0            0.0             416.0   \n",
       "\n",
       "        HOLIDAY_BINARY  Month  Hour  Date_time_week_ago  \\\n",
       "131400               0      1     0          2019-12-25   \n",
       "131401               0      1     0          2019-12-25   \n",
       "131402               0      1     0          2019-12-25   \n",
       "131403               0      1     0          2019-12-25   \n",
       "131404               0      1     0          2019-12-25   \n",
       "...                ...    ...   ...                 ...   \n",
       "392410               1     12     0          2021-12-19   \n",
       "392411               1     12     0          2021-12-19   \n",
       "392412               1     12     0          2021-12-19   \n",
       "392413               1     12     0          2021-12-19   \n",
       "392414               1     12     0          2021-12-19   \n",
       "\n",
       "        Checked_in_passengers_week_ago  Checked_out_passengers_week_ago  \n",
       "131400                           676.0                            339.0  \n",
       "131401                            31.0                            138.0  \n",
       "131402                            89.0                            154.0  \n",
       "131403                           102.0                            108.0  \n",
       "131404                            20.0                             12.0  \n",
       "...                                ...                              ...  \n",
       "392410                           201.0                            211.0  \n",
       "392411                            11.0                             39.0  \n",
       "392412                            30.0                             83.0  \n",
       "392413                            11.0                             17.0  \n",
       "392414                            13.0                             46.0  \n",
       "\n",
       "[261015 rows x 34 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "M_GVB_weather_events_all_covidindex_holidays_binary2020.to_csv(\"M_GVB_weather_events_all_covidindex_holidays_binary2020.csv\")\n",
    "M_GVB_weather_events_all_covidindex_holidays_binary2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e501f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60f5cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613c66f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418bd6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc556796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
